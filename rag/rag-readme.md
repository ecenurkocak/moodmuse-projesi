# ğŸ§  MoodMuse Bilgi BankasÄ± (RAG) Mimarisi

Bu dokÃ¼man, MoodMuse projesinin Retrieval-Augmented Generation (RAG) sisteminin teknik yapÄ±sÄ±nÄ±, iÅŸleyiÅŸini ve nasÄ±l yÃ¶netileceÄŸini aÃ§Ä±klamaktadÄ±r.

## ğŸ¯ AmaÃ§

Projenin RAG bileÅŸeninin temel amacÄ±, kullanÄ±cÄ±lara mindfulness, pozitif psikoloji ve ruh saÄŸlÄ±ÄŸÄ± gibi konularda gÃ¼venilir ve baÄŸlama uygun cevaplar sunan bir "bilgi bankasÄ±" oluÅŸturmaktÄ±r. Bu sistem, yapay zekanÄ±n serbestÃ§e cevap Ã¼retmesini engeller; bunun yerine, bizim saÄŸladÄ±ÄŸÄ±mÄ±z seÃ§kin dokÃ¼manlarÄ± bir bilgi kaynaÄŸÄ± olarak kullanarak daha doÄŸru ve tutarlÄ± yanÄ±tlar vermesini saÄŸlar.

## âš™ï¸ Mimari ve Ä°ÅŸleyiÅŸ

Sistemimiz iki ana aÅŸamadan oluÅŸur: **Veri YÃ¼kleme (Ingestion)** ve **Sorgulama (Querying)**.


### 1. Veri YÃ¼kleme (Ingestion) AÅŸamasÄ±

Bu aÅŸama, `python -m rag.ingest` komutu Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda gerÃ§ekleÅŸir ve bilgi bankasÄ±nÄ± hazÄ±rlar.

- **Kaynak DokÃ¼manlar:** Bilgi tabanÄ±nÄ± oluÅŸturan tÃ¼m kaynak PDF dosyalarÄ± `rag/source_documents/` klasÃ¶rÃ¼nde bulunur.
- **YÃ¼kleme (Loading):** `LangChain`'in `PyPDFDirectoryLoader`'Ä±, bu klasÃ¶rdeki tÃ¼m PDF'leri okur.
- **ParÃ§alama (Chunking):** Okunan metinler, `RecursiveCharacterTextSplitter` kullanÄ±larak daha kÃ¼Ã§Ã¼k ve anlamsal olarak tutarlÄ± parÃ§alara (chunks) ayrÄ±lÄ±r. Bu, arama doÄŸruluÄŸunu artÄ±rÄ±r.
- **VektÃ¶rleÅŸtirme (Embedding):** Her metin parÃ§asÄ±, `HuggingFaceEmbeddings` (spesifik olarak `all-MiniLM-L6-v2` modeli) kullanÄ±larak 384 boyutlu bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Bu vektÃ¶r, metnin anlamsal Ã¶zÃ¼nÃ¼ temsil eder.
- **Depolama (Storing):** OluÅŸturulan vektÃ¶rler ve orijinal metin parÃ§alarÄ±, `ChromaDB` vektÃ¶r veritabanÄ±na kaydedilir. VeritabanÄ± dosyalarÄ±, `db/chroma/` klasÃ¶rÃ¼nde kalÄ±cÄ± olarak saklanÄ±r.

### 2. Sorgulama (Querying) AÅŸamasÄ±

Bu aÅŸama, kullanÄ±cÄ± arayÃ¼zden bir soru sorduÄŸunda (`/api/v1/rag/query` endpoint'i aracÄ±lÄ±ÄŸÄ±yla) gerÃ§ekleÅŸir.

- **Sorgu VektÃ¶rleÅŸtirme:** KullanÄ±cÄ±nÄ±n sorduÄŸu soru, aynÄ± embedding modeli (`all-MiniLM-L6-v2`) kullanÄ±larak bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.
- **Benzerlik AramasÄ± (Retrieval):** `ChromaDB`, kullanÄ±cÄ±nÄ±n sorgu vektÃ¶rÃ¼ne en Ã§ok benzeyen (anlamsal olarak en ilgili) metin parÃ§alarÄ±nÄ± veritabanÄ±ndan bulur (`k=2` ayarÄ± ile en ilgili 2 parÃ§a alÄ±nÄ±r).
- **Cevap Ãœretimi (Generation):**
    - Bulunan ilgili metin parÃ§alarÄ± (baÄŸlam/context) ve kullanÄ±cÄ±nÄ±n orijinal sorusu, `rag_chain.py` dosyasÄ±nda tanÄ±mlanan bir prompt ÅŸablonuna yerleÅŸtirilir.
    - Bu birleÅŸtirilmiÅŸ metin, cevap Ã¼retmesi iÃ§in `text-generation-webui` aracÄ±lÄ±ÄŸÄ±yla sunulan yerel dil modeline (LLM) gÃ¶nderilir.
    - LLM, kendisine verilen baÄŸlamÄ± kullanarak soruya en uygun cevabÄ± Ã¼retir.

Bu yaklaÅŸÄ±m sayesinde, LLM'in "halÃ¼sinasyon gÃ¶rmesi" veya konu dÄ±ÅŸÄ± cevaplar vermesi engellenir ve cevaplarÄ±n bizim saÄŸladÄ±ÄŸÄ±mÄ±z kaynaklara dayalÄ± olmasÄ± saÄŸlanÄ±r.

## ğŸ› ï¸ Teknolojiler ve BileÅŸenler

- **Orkestrasyon:** `LangChain`
- **VektÃ¶r VeritabanÄ±:** `ChromaDB`
- **Embedding Modeli:** `HuggingFaceEmbeddings` (`sentence-transformers/all-MiniLM-L6-v2`)
- **Dil Modeli (LLM):** `text-generation-webui` Ã¼zerinden sunulan yerel bir model.
- **API Sunucusu:** `FastAPI`

## â• Bilgi BankasÄ±na Yeni DokÃ¼man NasÄ±l Eklenir?

1.  **PDF Ekleme:** Bilgi bankasÄ±na eklemek istediÄŸiniz yeni `.pdf` dosyasÄ±nÄ± `rag/source_documents/` klasÃ¶rÃ¼nÃ¼n iÃ§ine kopyalayÄ±n.
2.  **Veri YÃ¼kleme Komutunu Ã‡alÄ±ÅŸtÄ±rma:** Projenin ana dizinindeyken terminali aÃ§Ä±n ve aÅŸaÄŸÄ±daki komutu Ã§alÄ±ÅŸtÄ±rÄ±n:
    ```bash
    python -m rag.ingest
    ```
3.  **Ä°ÅŸlem TamamlandÄ±:** Bu komut, yeni eklediÄŸiniz PDF'i iÅŸleyecek, vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼recek ve `ChromaDB` veritabanÄ±na ekleyecektir. ArtÄ±k RAG sisteminiz, yeni eklediÄŸiniz belgedeki bilgileri kullanarak da cevaplar Ã¼retebilir.
